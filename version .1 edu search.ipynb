{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T00:57:52.412193Z",
     "start_time": "2018-07-10T00:57:51.323071Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\rishi\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'http://www.harvard.edu/searches/'}\n",
      "https://www.harvard.edu/searches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://www.harvard.edu/searches'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import httplib2\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "h = httplib2.Http(\".cache\",disable_ssl_certificate_validation=True)\n",
    "forbidden=set()\n",
    "class Invalid(RuntimeError):   \n",
    "    def __init__(self, message):      \n",
    "        self.message = message\n",
    "class Forbidden(RuntimeError):   \n",
    "    def __init__(self, message):      \n",
    "        self.message = message\n",
    "def clean(url,TLD=['.org','.net','.edu','.com','.int']):\n",
    "    if re.match(('^(https://www\\.).*(\\.(com|org|net|in|edu|int))$'),url.lower()):\n",
    "        return str(url)\n",
    "    else:\n",
    "        url=url.replace('www','').replace('https','').lstrip('.').lstrip(':').lstrip('//')\n",
    "        url='https://www.'+url\n",
    "        if (url.lower())[-4:] not in TLD:\n",
    "            raise Invalid('Invalid URL Top level domain name:clean')\n",
    "        return str(url)\n",
    "def search_url(uni,keyword):\n",
    "    resp,url_html=h.request('http://www.'+uni+'.edu')\n",
    "    bs_html=BeautifulSoup(url_html)\n",
    "    url=set()\n",
    "    if resp['status'] not in ['200','304']:\n",
    "        forbidden.add(resp['status']+':'+uni)\n",
    "        raise Forbidden('url forbidden:search_url')\n",
    "    tag=bs_html.find(action=re.compile('(.*)search(.*)$'))\n",
    "    if tag == None:\n",
    "        mid_url='http://www.'+uni+'.edu/search'\n",
    "        print('tag:'+mid_url)\n",
    "    else:\n",
    "        if tag.attrs['action'].find(uni+'.edu') < 0:\n",
    "            mid_url=('http://www.'+uni+'.edu'+tag.attrs['action'])\n",
    "        else:\n",
    "            mid_url=tag.attrs['action']\n",
    "    url.add(mid_url)\n",
    "    print(url)\n",
    "    if 'content-location' in list(h.request(mid_url)[0].keys()):\n",
    "        mid_url=(h.request(mid_url)[0])['content-location']\n",
    "        print(mid_url)\n",
    "    url.add(mid_url)\n",
    "    mid_bs=BeautifulSoup(h.request(mid_url)[1])\n",
    "    final_url=mid_url\n",
    "    for search in mid_bs.findAll('form',{'action':re.compile('^(http)(.*)search(.*)$')}):\n",
    "        if (search.attrs['action'] not in url) and ((search.attrs['action'].find(uni)) >-1 ):\n",
    "            final_url=search.attrs['action']\n",
    "    return (final_url.split('?'))[0]\n",
    "search_url('harvard','knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
