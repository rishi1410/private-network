{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T14:03:09.431896Z",
     "start_time": "2018-06-28T14:02:54.724128Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://googlesearch.northwestern.edu/search\n",
      "http://googlesearch.northwestern.edu/search?q=knn&start=0\n",
      "https://googlesearch.northwestern.edu/search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\rishi\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://googlesearch.northwestern.edu/search\n",
      "http://googlesearch.northwestern.edu/search?q=knn&start=5\n",
      "https://googlesearch.northwestern.edu/search\n",
      "https://googlesearch.northwestern.edu/search\n",
      "http://googlesearch.northwestern.edu/search?q=knn&start=10\n",
      "https://googlesearch.northwestern.edu/search\n",
      "https://googlesearch.northwestern.edu/search\n",
      "http://googlesearch.northwestern.edu/search?q=knn&start=15\n",
      "https://googlesearch.northwestern.edu/search\n",
      "https://googlesearch.northwestern.edu/search\n",
      "http://googlesearch.northwestern.edu/search?q=knn&start=20\n",
      "https://googlesearch.northwestern.edu/search\n",
      "http://users.eecs.northwestern.edu/~xsh835/assets/cvpr15_humanparsing.pdf\n",
      "https://arch.library.northwestern.edu/downloads/v118rd63p?locale=en\n",
      "http://users.eecs.northwestern.edu/~yingwu/teaching/EECS433/Reading/Weinberger_NISP06.pdf\n",
      "http://www.kellogg.northwestern.edu/career/employer/recruit-kellogg-talent/recruiting-calendars.aspx\n",
      "http://www.cs.northwestern.edu/~pardo/courses/eecs349/lectures/eecs349_memory_based_learning.pdf\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "import httplib2\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "h = httplib2.Http(\".cache\")\n",
    "def search_result(cx,key):\n",
    "    print('cx:'+cx)\n",
    "    print('GCSE link:https://www.googleapis.com/customsearch/v1?key=AIzaSyDntBXE_OmR09ZdYVOihpljooHe_KUCtNk&cx='+cx+'&q='+key)\n",
    "    url_html=h.request('https://www.googleapis.com/customsearch/v1?key=AIzaSyDntBXE_OmR09ZdYVOihpljooHe_KUCtNk&cx='+cx+'&q='+key)[1]\n",
    "    bs_obj=BeautifulSoup(url_html)\n",
    "    print(((bs_obj).p.get_text()))\n",
    "    return [link['link'] for link in dict((json.loads((bs_obj).p.get_text())))['items']]\n",
    "class GCSE(RuntimeError):   \n",
    "    def __init__(self, message):      \n",
    "        self.message = message\n",
    "def get_search_url(uni):\n",
    "    search_tag=BeautifulSoup((h.request('http://www.'+uni+'.edu'))[1],'html.parser').find(action=re.compile('.*search.*'))\n",
    "    if search_tag==None:\n",
    "        print('search result_search_tag:'+'http://www.'+uni+'.edu/search')\n",
    "        return 'http://www.'+uni+'.edu/search'\n",
    "    search_url=search_tag.attrs['action']\n",
    "    if re.match('.*'+uni+'\\.edu(.*)',search_url):\n",
    "        print(search_url)\n",
    "        redirec_url=urlopen(search_url).geturl().rstrip('\\.html')+'h'\n",
    "        return (redirec_url.split('?'))[0]\n",
    "    else:\n",
    "        return 'http://www.'+uni+'.edu'+search_url\n",
    "def search_edu(uni,keyword,num=5,typ=''):\n",
    "    keyword='+'.join(keyword.split(' '))\n",
    "    links=set()\n",
    "    try:\n",
    "        for i in range(num):\n",
    "            print(get_search_url(uni)+'?q='+keyword+'&start='+repr(i*num))\n",
    "            result=(BeautifulSoup((h.request(get_search_url(uni)+'?as_q='+keyword+'&start='+repr(i*num)))[1]))\n",
    "            tags_list=result.findAll('r',{'n':re.compile('[0-9]+')})\n",
    "            if not tags_list:\n",
    "                raise GCSE('GCSE')    \n",
    "            for link in tags_list:\n",
    "                if len(links)<num:\n",
    "                    if re.match('.*('+typ+')$',link.u.get_text()):\n",
    "                        links.add(link.u.get_text())\n",
    "                    else:\n",
    "                        return links\n",
    "        return links\n",
    "    except GCSE as gcse:\n",
    "        print(gcse.message)\n",
    "        result=BeautifulSoup(h.request(get_search_url(uni)+'?as_q='+keyword+'#gsc.tab=0&gsc.q='+keyword+'&gsc.page=1')[1])\n",
    "        for script in result.findAll('script'):\n",
    "            if script.get_text().find('cx') > 0:\n",
    "                print(script.attrs)\n",
    "                func=script.get_text()\n",
    "                break\n",
    "        url_cx=func[func.find('cx = ')+6:func.find(';\\n')-1]\n",
    "        return search_result(url_cx,keyword)\n",
    "def clean_content(content, n):\n",
    "    content = bytes(content, \"UTF-8\")\n",
    "    content = content.decode(\"ascii\", \"ignore\")   \n",
    "    content = re.sub('\\n+', \" \", content)\n",
    "    content = re.sub('\\[[0-9]+\\]',\" \",content)\n",
    "    content = re.sub(' +', \" \", content)  \n",
    "    print(content)\n",
    "    content_list = content.split(' ')    \n",
    "    output = []    \n",
    "    for item in content_list:        \n",
    "        item = item.strip(string.punctuation)\n",
    "        if len(item)>1 or (item.lower()=='a' or item.lower()=='i'):\n",
    "            output.append(item)\n",
    "    return output\n",
    "def ngrams(input, n):    \n",
    "    input = cleanInput(input)    \n",
    "    output = []    \n",
    "    for i in range(len(input)-n+1):        \n",
    "        output.append(input[i:i+n])    \n",
    "    return output\n",
    "def dic_ngrams(input,n):\n",
    "    ngram_list=ngram(input,n)\n",
    "    list_ngram_senten=[]\n",
    "    for word_list in ngram_list:\n",
    "        list_ngram_senten.append(' '.join(word_list))\n",
    "    return list_ngram_senten\n",
    "def getDownloadPath(baseUrl, absoluteUrl, downloadDirectory): \n",
    "    path = absoluteUrl.replace(\"www.\", \"\")\n",
    "    path = path.replace('https://','')\n",
    "    path=path.replace('http://','')\n",
    "    path = path.replace(baseUrl, \"\")\n",
    "    if not path.endswith('.pdf'):\n",
    "        path=path.split('?')[0]\n",
    "    path = downloadDirectory+path    \n",
    "    directory = os.path.dirname(path)\n",
    "    print(directory)\n",
    "    if not os.path.exists(directory):        \n",
    "        os.makedirs(directory)\n",
    "    return path\n",
    "for url in search_edu('northwestern','knn'):\n",
    "    print(url)\n",
    "    print(os.path.dirname())\n",
    "    try:\n",
    "        urlretrieve(url,os.path.dirname('knn/northwestern'))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
